{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "5b6bebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "fe8dcf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>reason</th>\n",
       "      <th>guardian</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mjob  Fjob  reason  guardian  studytime  failures  health  absences  G1  \\\n",
       "0       0     4       0         1          2         0       2         6   5   \n",
       "1       0     2       0         0          2         0       2         4   5   \n",
       "2       0     2       2         1          2         3       2        10   7   \n",
       "3       1     3       1         1          3         0       4         2  15   \n",
       "4       2     2       1         0          2         0       4         4   6   \n",
       "..    ...   ...     ...       ...        ...       ...     ...       ...  ..   \n",
       "390     3     3       0         2          2         2       3        11   9   \n",
       "391     3     3       0         1          1         0       1         3  14   \n",
       "392     2     2       0         2          1         3       2         3  10   \n",
       "393     3     2       0         1          1         0       4         0  11   \n",
       "394     2     0       0         0          1         0       4         5   8   \n",
       "\n",
       "     G2  \n",
       "0     6  \n",
       "1     5  \n",
       "2     8  \n",
       "3    14  \n",
       "4    10  \n",
       "..   ..  \n",
       "390   9  \n",
       "391  16  \n",
       "392   8  \n",
       "393  12  \n",
       "394   9  \n",
       "\n",
       "[395 rows x 10 columns]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"student-mat.csv\" , sep=\";\" )\n",
    "cols_to_drop = [\n",
    "    \"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"sex\",\n",
    "    \"traveltime\",\"age\", \"school\",\n",
    "    \"schoolsup\",\"famsup\",\"paid\",\"activities\",\"nursery\",\"higher\",\n",
    "    \"internet\",\"romantic\",\"famrel\",\"freetime\",\"goout\",\"Dalc\",\"Walc\"\n",
    "]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "data.drop(\n",
    "    columns=cols_to_drop,\n",
    "    inplace=True\n",
    "    )\n",
    "\n",
    "# # data.info()\n",
    "# data[\"reason\"] = data[\"reason\"].map({\n",
    "#     \"course\":int(0),\n",
    "#     \"home\":int(1),\n",
    "#     \"other\":int(2)\n",
    "# })\n",
    "\n",
    "\n",
    "data[\"reason\"] = label_encoder.fit_transform(data[\"reason\"])\n",
    "data[\"health\"] = label_encoder.fit_transform(data[\"health\"])\n",
    "\n",
    "\n",
    "# data.info()\n",
    "# data[\"guardian\"] = data[\"guardian\"].map({\n",
    "#     \"mother\":int(0),\n",
    "#     \"father\":int(1),\n",
    "# })\n",
    "\n",
    "\n",
    "data[\"guardian\"] = label_encoder.fit_transform(data[\"guardian\"])\n",
    "\n",
    "\n",
    "# data.replace(np.nan , 0 , inplace=True)\n",
    "label = data[\"G3\"]\n",
    "\n",
    "data.drop(columns=\"G3\" , inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "data[\"Mjob\"] = label_encoder.fit_transform(data[\"Mjob\"])\n",
    "data[\"Fjob\"] = label_encoder.fit_transform(data[\"Fjob\"])\n",
    "\n",
    "\n",
    "q1 = data[\"absences\"].quantile(0.25)\n",
    "q3 = data[\"absences\"].quantile(0.75)\n",
    "\n",
    "IQR = q3-q1\n",
    "\n",
    "upper = q3 + 1.5*IQR\n",
    "lower = q1 - 1.5*IQR\n",
    "\n",
    "\n",
    "data[\"absences\"]  = data[\"absences\"].clip(lower=lower , upper=upper)\n",
    "\n",
    "\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "c9f433ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(data , label , test_size=0.2 , random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "RS = StandardScaler()\n",
    "xtrain[\"absences\"] = RS.fit_transform(xtrain[[\"absences\"]])\n",
    "xtest[\"absences\"] = RS.transform(xtest[[\"absences\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "05656b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  (237.48398302130337, -10.306329425803744)\n",
      "Loss :  (3.211274833657454, 0.8471150319941058)\n",
      "Loss :  (2.748151040107659, 0.8691638039078402)\n",
      "Loss :  (2.2829617297791334, 0.891310912613967)\n",
      "Loss :  (1.962848762906251, 0.9065511094933142)\n",
      "Loss :  (1.5977440134617529, 0.9239333115249128)\n",
      "Loss :  (1.4719111774897338, 0.9299240628925751)\n",
      "Loss :  (1.4435957135799897, 0.9312721283862354)\n",
      "Loss :  (1.3099918779041924, 0.9376328477892193)\n",
      "Loss :  (1.194809835749069, 0.9431165275556389)\n",
      "Loss :  (1.0311943108570953, 0.950906067717758)\n",
      "Loss :  (0.9960244761129011, 0.952580461638603)\n",
      "Loss :  (0.9831542773721715, 0.9531931964634404)\n",
      "Loss :  (0.8590768035493963, 0.959100377131014)\n",
      "Loss :  (0.9412181188578479, 0.9551897269956622)\n",
      "Loss :  (0.715546550363913, 0.9659336814424822)\n",
      "Loss :  (0.8642628904068204, 0.9588534737159083)\n",
      "Loss :  (0.8046202373669903, 0.9616929893519449)\n",
      "Loss :  (0.695215827016587, 0.9669016029532526)\n",
      "Loss :  (0.7932469911791926, 0.9622344560496315)\n",
      "Loss PREDS - YTEST :  (37.57616830768965, 0     -0.832533\n",
      "3      1.000000\n",
      "5      1.000000\n",
      "9      1.000000\n",
      "15     1.000000\n",
      "         ...   \n",
      "384    1.000000\n",
      "386    1.000000\n",
      "390    1.000000\n",
      "391    1.000000\n",
      "393    1.000000\n",
      "Length: 79, dtype: float64)\n",
      "Model prediction :               0\n",
      "78    6.816752\n",
      "371  12.246363\n",
      "248   4.297577\n",
      "55    8.797048\n",
      "390   9.034911\n",
      "..         ...\n",
      "364  10.996714\n",
      "82    5.720242\n",
      "114   8.578168\n",
      "3    13.853433\n",
      "18    5.287481\n",
      "\n",
      "[79 rows x 1 columns]\n",
      "Actual values :  78     10\n",
      "371    12\n",
      "248     5\n",
      "55     10\n",
      "390     9\n",
      "       ..\n",
      "364    12\n",
      "82      6\n",
      "114     9\n",
      "3      15\n",
      "18      5\n",
      "Name: G3, Length: 79, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\envs\\torchgpu\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "from numpy import ndarray\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self , X ,in_features=10 ,  hidden_layer_one=32 , hidden_layer_two=16 , out_features=1 , lr=1e-4):\n",
    "        # Xaiver \n",
    "        # Use He initialization for ReLU\n",
    "        self.w1 = np.random.randn(in_features, hidden_layer_one) * np.sqrt(2/in_features)\n",
    "        self.w2 = np.random.randn(hidden_layer_one, hidden_layer_two) * np.sqrt(2/hidden_layer_one)\n",
    "        self.w3 = np.random.randn(hidden_layer_two, out_features) * np.sqrt(2/hidden_layer_two)\n",
    "        \n",
    "        self.b1 = np.zeros((1 , hidden_layer_one))\n",
    "        self.b2 = np.zeros((1 , hidden_layer_two))\n",
    "        self.b3 = np.zeros((1 , out_features))\n",
    "        self.lr = lr\n",
    "    \n",
    "    def relu(self, x:ndarray):\n",
    "        return np.maximum(0,x)\n",
    "    \n",
    "    def relu_derivative(self, x:ndarray):\n",
    "        return (x > 0).astype(float)\n",
    "    \n",
    "    def forward(self , x:ndarray):\n",
    "        self.z1 = x@self.w1 + self.b1\n",
    "        self.A1 = self.relu(self.z1)\n",
    "        self.z2 = self.A1@self.w2 + self.b2\n",
    "        self.A2 = self.relu(self.z2)\n",
    "        self.z3 = self.A2@self.w3 + self.b3\n",
    "        self.y_hat = self.z3\n",
    "        return self.y_hat\n",
    "        \n",
    "    def loss(self , y_hat:ndarray , y:ndarray): \n",
    "        MSE = np.mean((y_hat - y) ** 2)\n",
    "        ss_res = np.sum((y - y_hat) ** 2)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "        RSQE = 1 - (ss_res / ss_tot)\n",
    "\n",
    "        return MSE , RSQE\n",
    "        \n",
    "    def backward(self, X , y_hat:ndarray , y:ndarray):\n",
    "        m = y.shape[0]\n",
    "        self.dz3 = (2/m)*(y_hat - y)\n",
    "        dw3 = self.A2.T @ self.dz3\n",
    "        db3 = np.sum(self.dz3 , axis=0 )\n",
    "        \n",
    "        self.dA2 = self.dz3 @ self.w3.T\n",
    "        self.dz2 = self.dA2 * self.relu_derivative(self.z2)\n",
    "        dw2 = self.A1.T @ self.dz2\n",
    "        db2 = np.sum(self.dz2 , axis=0 )\n",
    "        \n",
    "        \n",
    "        self.dA1 = self.dz2 @ self.w2.T\n",
    "        self.dz1 = self.dA1 * self.relu_derivative(self.z1)\n",
    "        dw1 = X.T @ self.dz1\n",
    "        db1 = np.sum(self.dz1 , axis=0 )\n",
    "        \n",
    "        return dw1 , db1 , dw2 , db2 , dw3,db3\n",
    "\n",
    "    def optim(self, dw1, db1, dw2, db2, dw3, db3):\n",
    "        self.w1 = self.w1 - self.lr*dw1\n",
    "        self.w2 = self.w2 - self.lr*dw2\n",
    "        self.w3 = self.w3 - self.lr*dw3\n",
    "        \n",
    "        self.b1 = self.b1 - self.lr*db1\n",
    "        self.b2 = self.b2 - self.lr*db2\n",
    "        self.b3 = self.b3 - self.lr*db3\n",
    "        \n",
    "    \n",
    "    def train(self, xtrain:ndarray , ytrain:ndarray , epoch):\n",
    "        \n",
    "        \n",
    "        for i in range(epoch):\n",
    "            y_pred = self.forward(xtrain)\n",
    "            \n",
    "            dw1 , db1 , dw2 , db2 , dw3,db3 = self.backward( xtrain, y_pred , ytrain)\n",
    "            \n",
    "            self.optim( dw1, db1, dw2, db2, dw3, db3)\n",
    "            \n",
    "            if i % 1000 == 0 :\n",
    "                print(\"Loss : \" , self.loss(y_pred , ytrain))\n",
    "                \n",
    "                \n",
    "    def predict(self, X):\n",
    "        predictions = self.forward(X)\n",
    "        return predictions     \n",
    "    \n",
    "def main():\n",
    "    X_train = xtrain.values\n",
    "    # X_test  = xtest.values\n",
    "\n",
    "\n",
    "    y_train = ytrain.values.reshape(-1, 1)\n",
    "    y_test  = ytest.values.reshape(-1, 1)\n",
    "\n",
    "    in_features = X_train.shape[1]\n",
    "\n",
    "    nn = NeuralNetwork(\n",
    "        X_train,\n",
    "        in_features=in_features,\n",
    "        lr=1e-3\n",
    "    )\n",
    "\n",
    "    nn.train(X_train, y_train, epoch=20000)\n",
    "\n",
    "    preds = nn.predict(xtest)\n",
    "    print(\"Loss PREDS - YTEST : \" ,nn.loss(preds , ytest) ) \n",
    "    print( \"Model prediction : \" , preds)\n",
    "    print(\"Actual values : \" , ytest)\n",
    "\n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
