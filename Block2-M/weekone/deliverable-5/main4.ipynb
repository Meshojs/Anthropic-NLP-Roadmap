{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81cb2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import torch as t \n",
    "from torch.utils.data import TensorDataset , DataLoader \n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self , training_data , testing_data): \n",
    "        self.stop_words = stopwords.words(\"english\")\n",
    "        self.data = training_data \n",
    "        self.testing_data = testing_data\n",
    "        self.model = None\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def load_clean_csv(self):\n",
    "        \n",
    "        assert len(self.data) != 0\n",
    "        \n",
    "        df = pd.read_csv(self.data)\n",
    "        df = df[~df[\"label\"].isin([4, 5])]\n",
    "        \n",
    "        min_sample = 1300\n",
    "        df = df.groupby(\"label\" , group_keys=False).sample(\n",
    "            min_sample , \n",
    "            random_state=42 , \n",
    "            replace=True\n",
    "        ) \n",
    "        \n",
    "        fixed_text = []\n",
    "        for sentence in df[\"text\"]:\n",
    "            review = sentence.lower()\n",
    "            review = review.split()\n",
    "\n",
    "            final = [WordNetLemmatizer().lemmatize(word) for word in review if word not in self.stop_words]\n",
    "            fixed_text.append(\" \".join(final))\n",
    "        \n",
    "        df[\"preprocessed_text\"] = fixed_text\n",
    "        \n",
    "        df.drop(columns=[\"text\"] ,inplace=True)\n",
    "        \n",
    "        self.data = df\n",
    "        \n",
    "    def train_vectorize(self):\n",
    "        self.cv = CountVectorizer(ngram_range=(1,2))\n",
    "        X = self.cv.fit_transform(self.data[\"preprocessed_text\"])\n",
    "        y = self.data[\"label\"].values\n",
    "        print(X.shape)\n",
    "        return X, y  \n",
    "    \n",
    "    def test_vectorize(self):\n",
    "        cv = CountVectorizer(ngram_range=(1,2))\n",
    "        Y = cv.transform(self.data[\"preprocessed_text\"])\n",
    "        return Y\n",
    "\n",
    "    def create_model(self , in_features , out_features):\n",
    "        class EmotionClassifier(t.nn.Module):\n",
    "            def __init__(self , infeatures , out_features):\n",
    "                super().__init__()\n",
    "                self.network = t.nn.Sequential(\n",
    "                    t.nn.Linear(infeatures, 256),\n",
    "                    t.nn.ReLU(),\n",
    "                    t.nn.Dropout(0.3),\n",
    "                    t.nn.Linear(256, 128),\n",
    "                    t.nn.ReLU(),\n",
    "                    t.nn.Dropout(0.3),\n",
    "                    t.nn.Linear(128, out_features)\n",
    "                )\n",
    "            def forward(self , x):\n",
    "                return self.network(x)\n",
    "        \n",
    "        return EmotionClassifier(in_features ,out_features)\n",
    "        # y long\n",
    "        # x float\n",
    "    def train(self , epochs , batch_size ,lr=0.0001):\n",
    "        self.load_clean_csv()\n",
    "        xtrain , ytrain = self.train_vectorize()\n",
    "        xtrain = xtrain.toarray()\n",
    "        device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "        print(\"training on :\" + device)\n",
    "        X_tensor = t.FloatTensor(xtrain ).to(device)    \n",
    "        Y_tensor = t.LongTensor(ytrain ).to(device)    \n",
    "        \n",
    "        dataset = TensorDataset(X_tensor , Y_tensor )\n",
    "        \n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size , shuffle=True)\n",
    "        num_classes = len(np.unique(ytrain))\n",
    "        self.model = self.create_model(xtrain.shape[1] ,num_classes ).to(device)\n",
    "        \n",
    "        c = t.nn.CrossEntropyLoss()\n",
    "        optim = t.optim.Adam(self.model.parameters() , lr=lr)\n",
    "        \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for idx , (batch_x , batch_y) in enumerate(train_loader):\n",
    "                y_pred = self.model(batch_x)\n",
    "                loss = c(y_pred , batch_y)\n",
    "\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                \n",
    "\n",
    "                all_preds.append(y_pred.argmax(dim=1).cpu())\n",
    "                all_labels.append(batch_y.cpu())\n",
    "\n",
    "                if idx % 50 == 0 :\n",
    "                    print(f\"Epoch {epoch}, Batch {idx}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "        all_preds = t.cat(all_preds)\n",
    "        all_labels = t.cat(all_labels)\n",
    "\n",
    "        cr = classification_report(all_labels.numpy(), all_preds.numpy())\n",
    "        cm = confusion_matrix(all_labels.numpy(), all_preds.numpy())\n",
    "        print(cr)\n",
    "        print(cm)\n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, text):\n",
    "\n",
    "        review = text.lower().split()\n",
    "        final = [self.lemmatizer.lemmatize(word) for word in review if word not in self.stop_words]\n",
    "        clean_text = \" \".join(final)\n",
    "        \n",
    "\n",
    "        X = self.cv.transform([clean_text]).toarray()\n",
    "\n",
    "        device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "        X_tensor = t.FloatTensor(X).to(device)\n",
    "        \n",
    "\n",
    "        self.model.eval()\n",
    "        with t.no_grad():\n",
    "            output = self.model(X_tensor)\n",
    "            pred = output.argmax(dim=1).item()\n",
    "            probabilities = t.nn.functional.softmax(output, dim=1)\n",
    "        \n",
    "        return pred, probabilities.cpu().numpy()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ecf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5200, 34103)\n",
      "training on :cuda\n",
      "Epoch 0, Batch 0, Loss: 1.3855\n",
      "Epoch 0, Batch 50, Loss: 1.3819\n",
      "Epoch 1, Batch 0, Loss: 1.3714\n",
      "Epoch 1, Batch 50, Loss: 1.3434\n",
      "Epoch 2, Batch 0, Loss: 1.2656\n",
      "Epoch 2, Batch 50, Loss: 1.1063\n",
      "Epoch 3, Batch 0, Loss: 0.9062\n",
      "Epoch 3, Batch 50, Loss: 0.6483\n",
      "Epoch 4, Batch 0, Loss: 0.4721\n",
      "Epoch 4, Batch 50, Loss: 0.3277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      6500\n",
      "           1       0.63      0.89      0.74      6500\n",
      "           2       0.89      0.80      0.84      6500\n",
      "           3       0.99      0.64      0.78      6500\n",
      "\n",
      "    accuracy                           0.78     26000\n",
      "   macro avg       0.82      0.78      0.79     26000\n",
      "weighted avg       0.82      0.78      0.79     26000\n",
      "\n",
      "[[5200 1202   80   18]\n",
      " [ 411 5795  285    9]\n",
      " [ 264 1031 5205    0]\n",
      " [ 830 1208  277 4185]]\n",
      "Predicted class: 3\n",
      "Probabilities: [[0.22413659 0.13713335 0.15775715 0.480973  ]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\"training.csv\", \"test.csv\")\n",
    "pipeline.train(epochs=5, batch_size=64)\n",
    "\n",
    "\n",
    "text = \"I am so angry about this!\"\n",
    "pred_class, probs = pipeline.predict(text)\n",
    "print(f\"Predicted class: {pred_class}\")\n",
    "print(f\"Probabilities: {probs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
